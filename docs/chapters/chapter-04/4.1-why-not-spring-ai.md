# 4.1 为什么不用 Spring AI？

> 本节讨论为什么 MiniClaw 选择自己实现 LLM 客户端，而不是使用 Spring AI。

## 本节目标

- 理解 Spring AI 的优劣势
- 理解手写 LLM 客户端的价值
- 做出合理的技术选型决策

## 本节要点

Spring AI 是 Spring 官方推出的 AI 集成框架，提供统一的 API 接口，支持多种 LLM（OpenAI、Anthropic、Ollama 等），与 Spring 生态无缝集成。

听起来不错，但我们在学习，不是在赶工期。

---

## Spring AI vs 手写实现对比

### Spring AI 的优势

| 优势 | 说明 | 适用场景 |
|------|------|----------|
| 开箱即用 | 无需写代码，配置即可使用 | 快速原型 |
| 统一接口 | 切换模型只需改配置 | 多模型切换 |
| 生态完整 | 集成向量库、RAG 等 | 企业应用 |
| 社区支持 | 文档丰富，问题易解决 | 团队协作 |

### Spring AI 的问题

| 问题 | 影响 | 学习视角 |
|------|------|----------|
| 抽象过度 | 不知道底层发生了什么 | 无法理解原理 |
| 灵活性差 | 自定义逻辑困难 | 受限于框架设计 |
| 版本依赖 | API 变化频繁 | 维护成本高 |
| 调试困难 | 黑盒效应 | 问题难以定位 |

### 手写实现的优势

| 优势 | 学习价值 |
|------|----------|
| 完全可控 | 每一行代码都清楚在做什么 |
| 深度理解 | 理解 LLM API 协议、流式输出、错误处理 |
| 灵活定制 | 可以随意修改和扩展 |
| 技术提升 | 掌握 HTTP 客户端、响应式编程 |

---

## 真实案例对比

### 场景 1：流式输出

**Spring AI：**

```java
@GetMapping("/stream")
public Flux<String> stream(@RequestParam String question) {
    return chatClient.stream(question);  // 一行代码搞定
}
```

**手写实现：**

```java
@GetMapping("/stream")
public Flux<LlmChunk> stream(@RequestParam String question) {
    // 1. 构建请求
    LlmRequest request = LlmRequest.builder()
        .messages(List.of(new Message("user", question)))
        .build();

    // 2. 调用 LLM
    return llmClient.stream(request)
        .doOnNext(chunk -> log.debug("收到 chunk: {}", chunk))
        .doOnError(error -> log.error("流式输出错误", error))
        .doOnComplete(() -> log.info("流式输出完成"));
}
```

差异很明显：Spring AI 一行代码，但内部做了什么完全不知道。手写版本复杂一些，但每一步都清清楚楚。

### 场景 2：错误处理

**Spring AI：**

```java
try {
    return chatClient.call(question);
} catch (Exception e) {
    // 框架异常，难以定位问题
    throw new RuntimeException("AI 调用失败", e);
}
```

**手写实现：**

```java
try {
    return llmClient.chat(request);
} catch (RateLimitException e) {
    // 限流错误
    return handleRateLimit(request, e);
} catch (TokenLimitException e) {
    // token 超限
    return handleTokenLimit(request, e);
} catch (TimeoutException e) {
    // 超时
    return handleTimeout(request, e);
}
```

Spring AI 抛出统一异常，你很难知道具体发生了什么。手写版本可以精确区分不同类型的错误，针对性处理。

### 场景 3：性能优化

**Spring AI：**

```java
// 框架自动管理，无法优化
```

**手写实现：**

```java
// 可以精确控制每个细节
Flux<LlmChunk> stream = llmClient.stream(request)
    .bufferTimeout(10, Duration.ofMillis(100))  // 缓冲优化
    .flatMap(this::processChunk)                 // 并行处理
    .onBackpressureBuffer(1000);                // 背压控制
```

框架是黑盒，你想优化都不知道从哪里下手。自己的代码，每一处都可以调整。

---

## 真实数据对比

### 开发效率

| 指标 | Spring AI | 手写实现 |
|------|-----------|----------|
| 原型开发 | 1 小时 | 1 天 |
| 功能完善 | 1 周 | 2 周 |
| 深度理解 | 无 | 完整 |
| 问题排查 | 困难 | 清晰 |

### 生产案例

**某金融公司（使用 Spring AI）：**

流式输出偶尔卡住，不知道原因。查来查去发现是框架内部 bug，无法深入排查。最后升级框架版本，耗时两周，期间影响线上服务。

**某电商公司（手写实现）：**

Token 统计不准确，10 分钟定位到问题（自己写的代码，哪里有问题一目了然），1 小时修复上线，几乎没影响。

---

## 学习视角的价值

### 为什么要学手写？

**面试的时候：**

"你用过 Spring AI 吗？" ——"用过。"
"你知道它底层是怎么实现的吗？" ——"呃……"

只会用框架和懂原理，差距就在这里。

**职业发展：**

- 初级：会用框架
- 中级：懂原理，能定制
- 高级：能造轮子，能优化

**技术深度：**

理解 HTTP 客户端怎么用，掌握响应式编程，深入 LLM 协议。这些东西框架帮不了你。

### 什么时候用 Spring AI？

**适合：**

- 快速验证想法（POC）
- 非核心业务（内部工具）
- 团队不熟悉 LLM（降低门槛）
- 时间紧迫（快速交付）

**不适合：**

- 学习目的（理解原理）
- 核心业务（需要深度定制）
- 性能敏感（需要优化）
- 特殊需求（框架不支持）

---

## MiniClaw 的设计哲学

MiniClaw 选择手写 LLM 客户端，遵循几个原则：

### 控制力比便利性重要

```java
// 宁愿多写几行代码，也要完全可控
public interface LlmClient {
    LlmResponse chat(LlmRequest request);
    Flux<LlmChunk> stream(LlmRequest request);
}
```

### 理解比使用重要

```java
// 不只是调用 API，而是理解协议
public class OpenAiCompatibleLlmClient implements LlmClient {
    // 理解 HTTP 请求如何构建
    // 理解 SSE 协议如何工作
    // 理解错误如何处理
}
```

### 可定制比开箱即用重要

```java
// 可以随意扩展和修改
public class LlmRequest {
    private List<Message> messages;
    private Map<String, Object> metadata;  // 自定义字段
    private Duration timeout;              // 自定义超时
    private Integer retryCount;            // 自定义重试
}
```

---

## 打个比方：打车 vs 开车

Spring AI 就像打车：方便，不需要懂车，但路线你说了不算，出了问题你也没法修。

手写实现就像自己开车：需要学驾驶，需要维护车辆，但去哪里、怎么走，完全由你决定，出了问题自己能动手。

MiniClaw 是学驾驶。我们不是为了快速到达目的地，而是为了掌握驾驶技术。

---

## Spring AI 的实际应用

虽然 MiniClaw 不用 Spring AI，但它确实是个好框架，用对了场景能省很多事。

**适合的场景：**

- 企业内部工具，快速搭建 AI 助手
- 原型验证，MVP 开发，演示 Demo
- 非核心业务，AI 辅助功能，不影响主流程

**不推荐的场景：**

- 学习目的——无法深入理解
- 核心业务——定制性差
- 高性能要求——优化困难

---

## 本节总结

| 维度 | Spring AI | 手写实现 |
|------|-----------|----------|
| 开发速度 | 快 | 慢 |
| 学习价值 | 低 | 高 |
| 灵活性 | 低 | 高 |
| 可控性 | 低 | 高 |
| 维护成本 | 中 | 高 |

MiniClaw 选择手写实现，因为目标是学习，不是快速交付。

你的选择取决于实际情况：

- 学习目的 → 手写实现
- 快速交付 → Spring AI
- 核心业务 → 手写实现
- 非核心功能 → Spring AI

---

## 扩展阅读

- [Spring AI 官方文档](https://docs.spring.io/spring-ai/)
- [OpenAI API 文档](https://platform.openai.com/docs)
- [响应式编程实战](https://projectreactor.io/)

---

## 下一节

下一节我们将设计 OpenAI 兼容客户端，定义 LlmClient 接口，理解 LLM API 协议。

[下一节：4.2 OpenAI 兼容客户端设计 →](./4.2-openai-compatible-client.md)
