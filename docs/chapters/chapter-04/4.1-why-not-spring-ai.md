# 4.1 为什么不用 Spring AI？

> 本节我们讨论为什么 MiniClaw 选择自己实现 LLM 客户端，而不是使用 Spring AI。

## 📋 本节目标

- 理解 Spring AI 的优劣势
- 理解手写 LLM 客户端的价值
- 做出合理的技术选型决策

## 🎯 本节要点

**Spring AI 是什么？**

Spring AI 是 Spring 官方推出的 AI 集成框架，提供：
- 统一的 API 接口
- 支持多种 LLM（OpenAI、Anthropic、Ollama 等）
- 与 Spring 生态无缝集成

**听起来很完美，为什么不用？**

因为我们在**学习**，而不是**快速交付**。

---

## ⚖️ Spring AI vs 手写实现对比

### Spring AI 的优势

| 优势 | 说明 | 适用场景 |
|------|------|----------|
| **开箱即用** | 无需写代码，配置即可使用 | 快速原型 |
| **统一接口** | 切换模型只需改配置 | 多模型切换 |
| **生态完整** | 集成向量库、RAG 等 | 企业应用 |
| **社区支持** | 文档丰富，问题易解决 | 团队协作 |

### Spring AI 的问题

| 问题 | 影响 | 学习视角 |
|------|------|----------|
| **抽象过度** | 不知道底层发生了什么 | ❌ 无法理解原理 |
| **灵活性差** | 自定义逻辑困难 | ❌ 受限于框架设计 |
| **版本依赖** | API 变化频繁 | ❌ 维护成本高 |
| **调试困难** | 黑盒效应 | ❌ 问题难以定位 |

### 手写实现的优势

| 优势 | 学习价值 |
|------|----------|
| **完全可控** | 每一行代码都清楚在做什么 |
| **深度理解** | 理解 LLM API 协议、流式输出、错误处理 |
| **灵活定制** | 可以随意修改和扩展 |
| **技术提升** | 掌握 HTTP 客户端、响应式编程 |

---

## 📊 真实案例对比

### 场景 1：流式输出

**Spring AI：**

```java
@GetMapping("/stream")
public Flux<String> stream(@RequestParam String question) {
    return chatClient.stream(question);  // 一行代码搞定
}
```

**手写实现：**

```java
@GetMapping("/stream")
public Flux<LlmChunk> stream(@RequestParam String question) {
    // 1. 构建请求
    LlmRequest request = LlmRequest.builder()
        .messages(List.of(new Message("user", question)))
        .build();

    // 2. 调用 LLM
    return llmClient.stream(request)
        .doOnNext(chunk -> log.debug("收到 chunk: {}", chunk))
        .doOnError(error -> log.error("流式输出错误", error))
        .doOnComplete(() -> log.info("流式输出完成"));
}
```

**差异：**
- Spring AI：简单，但不知道内部如何处理
- 手写：复杂，但清楚每一步在做什么

### 场景 2：错误处理

**Spring AI：**

```java
try {
    return chatClient.call(question);
} catch (Exception e) {
    // 框架异常，难以定位问题
    throw new RuntimeException("AI 调用失败", e);
}
```

**手写实现：**

```java
try {
    return llmClient.chat(request);
} catch (RateLimitException e) {
    // 清晰知道是限流错误
    return handleRateLimit(request, e);
} catch (TokenLimitException e) {
    // 清晰知道是 token 超限
    return handleTokenLimit(request, e);
} catch (TimeoutException e) {
    // 清晰知道是超时
    return handleTimeout(request, e);
}
```

**差异：**
- Spring AI：统一异常，难以细分处理
- 手写：精确异常类型，针对性处理

### 场景 3：性能优化

**Spring AI：**

```java
// 框架自动管理，无法优化
```

**手写实现：**

```java
// 可以精确控制每个细节
Flux<LlmChunk> stream = llmClient.stream(request)
    .bufferTimeout(10, Duration.ofMillis(100))  // 缓冲优化
    .flatMap(this::processChunk)                 // 并行处理
    .onBackpressureBuffer(1000);                // 背压控制
```

**差异：**
- Spring AI：无法优化（黑盒）
- 手写：完全可控，可以针对性优化

---

## 💡 真实数据对比

### 开发效率

| 指标 | Spring AI | 手写实现 |
|------|-----------|----------|
| **原型开发** | 1 小时 | 1 天 |
| **功能完善** | 1 周 | 2 周 |
| **深度理解** | ❌ 无 | ✅ 完整 |
| **问题排查** | ❌ 困难 | ✅ 清晰 |

### 生产案例

**某金融公司（使用 Spring AI）：**

- **问题**：流式输出偶尔卡住，不知道原因
- **定位**：框架内部错误，无法深入排查
- **解决**：升级框架版本（耗时 2 周）
- **成本**：影响线上服务

**某电商公司（手写实现）：**

- **问题**：Token 统计不准确
- **定位**：10 分钟找到问题（自己写的代码）
- **解决**：1 小时修复并优化
- **成本**：几乎无影响

---

## 🎓 学习视角的价值

### 为什么要学手写？

1. **面试加分**
   - "你用过 Spring AI 吗？"
   - "你知道它底层是怎么实现的吗？"
   - 只会用 vs 懂原理，差距明显

2. **职业发展**
   - 初级：会用框架
   - 中级：懂原理，能定制
   - 高级：能造轮子，能优化

3. **技术深度**
   - 理解 HTTP 客户端
   - 掌握响应式编程
   - 深入 LLM 协议

### 什么时候用 Spring AI？

**适合用 Spring AI 的场景：**

- ✅ 快速验证想法（POC）
- ✅ 非核心业务（内部工具）
- ✅ 团队不熟悉 LLM（降低门槛）
- ✅ 时间紧迫（快速交付）

**不适合用 Spring AI 的场景：**

- ❌ 学习目的（理解原理）
- ❌ 核心业务（需要深度定制）
- ❌ 性能敏感（需要优化）
- ❌ 特殊需求（框架不支持）

---

## 🏗️ MiniClaw 的设计哲学

MiniClaw 选择手写 LLM 客户端，遵循以下原则：

### 1. 控制力 > 便利性

```java
// 宁愿多写几行代码，也要完全可控
public interface LlmClient {
    LlmResponse chat(LlmRequest request);
    Flux<LlmChunk> stream(LlmRequest request);
}
```

### 2. 理解 > 使用

```java
// 不只是调用 API，而是理解协议
public class OpenAiCompatibleLlmClient implements LlmClient {
    // 理解 HTTP 请求如何构建
    // 理解 SSE 协议如何工作
    // 理解错误如何处理
}
```

### 3. 可定制 > 开箱即用

```java
// 可以随意扩展和修改
public class LlmRequest {
    private List<Message> messages;
    private Map<String, Object> metadata;  // 自定义字段
    private Duration timeout;              // 自定义超时
    private Integer retryCount;            // 自定义重试
}
```

---

## 📚 类比：打车 vs 开车

**Spring AI = 打车**
- ✅ 方便快捷
- ✅ 不需要懂车
- ❌ 无法控制路线
- ❌ 出问题难处理

**手写实现 = 开车**
- ❌ 需要学习驾驶
- ❌ 需要维护车辆
- ✅ 完全控制路线
- ✅ 出问题能自己修

**MiniClaw = 学驾驶**
我们不是为了快速到达目的地，而是为了掌握驾驶技术。

---

## 🔍 Spring AI 的实际应用

虽然 MiniClaw 不使用 Spring AI，但它依然是一个优秀的框架：

**适合的场景：**

1. **企业内部工具**
   - 快速搭建 AI 助手
   - 不需要深度定制
   - 团队协作友好

2. **原型验证**
   - 快速验证想法
   - MVP 开发
   - 演示 Demo

3. **非核心业务**
   - AI 辅助功能
   - 内部工具
   - 不影响主流程

**不推荐在以下场景使用：**

1. **学习目的** - 无法深入理解
2. **核心业务** - 定制性差
3. **高性能要求** - 优化困难

---

## 🎯 本节总结

### 关键决策

| 维度 | Spring AI | 手写实现 |
|------|-----------|----------|
| **开发速度** | ⭐⭐⭐⭐⭐ | ⭐⭐ |
| **学习价值** | ⭐ | ⭐⭐⭐⭐⭐ |
| **灵活性** | ⭐⭐ | ⭐⭐⭐⭐⭐ |
| **可控性** | ⭐ | ⭐⭐⭐⭐⭐ |
| **维护成本** | ⭐⭐⭐ | ⭐⭐ |

### MiniClaw 的选择

✅ **手写实现** - 因为我们的目标是学习，而不是快速交付。

### 你的选择

根据实际情况选择：

- **学习目的** → 手写实现（MiniClaw 方案）
- **快速交付** → Spring AI（框架方案）
- **核心业务** → 手写实现（深度定制）
- **非核心功能** → Spring AI（快速集成）

---

## 📖 扩展阅读

- [Spring AI 官方文档](https://docs.spring.io/spring-ai/)
- [OpenAI API 文档](https://platform.openai.com/docs)
- [响应式编程实战](https://projectreactor.io/)

---

## 🚀 下一节

下一节我们将：
- 设计 OpenAI 兼容客户端
- 定义 LlmClient 接口
- 理解 LLM API 协议

[下一节：4.2 OpenAI 兼容客户端设计 →](./4.2-openai-compatible-client.md)
