# 4.5 错误处理与降级策略

> 本节我们为 LLM 客户端添加错误处理和重试机制。

## 本节目标

- 实现重试机制（指数退避）
- 区分可重试和不可重试错误
- 流式调用的错误降级
- 添加完善的单元测试

## 为什么需要错误处理？

**调用 LLM API 可能遇到的错误：**

| 错误类型 | 状态码 | 是否可重试 | 原因 |
|---------|--------|----------|------|
| 服务器错误 | 500/502/503/504 | ✅ 是 | 临时故障，稍后可能恢复 |
| 限流 | 429 | ✅ 是 | 请求太快，等待后重试 |
| 超时 | - | ✅ 是 | 网络问题，重试可能成功 |
| 客户端错误 | 400/401/404 | ❌ 否 | 请求本身有问题，重试无意义 |

## 实现重试机制

### 同步调用重试

```java
@Override
public LlmResponse chat(LlmRequest request) {
    String responseBody = webClient.post()
        .uri("/chat/completions")
        .bodyValue(apiRequest)
        .retrieve()
        .bodyToMono(String.class)
        .timeout(Duration.ofSeconds(properties.getTimeout()))
        .retryWhen(Retry.backoff(3, Duration.ofSeconds(1))
            .maxBackoff(Duration.ofSeconds(10))
            .filter(throwable -> isRetryableError(throwable))
            .onRetryExhaustedThrow((spec, signal) ->
                new LlmException("Max retries exceeded")))
        .block();

    return parseResponse(responseBody);
}
```

**重试策略：**
- 最多重试 3 次
- 初始等待 1 秒
- 最大等待 10 秒（指数退避）
- 只重试可恢复的错误

### 流式调用重试

```java
@Override
public Flux<LlmChunk> stream(LlmRequest request) {
    return webClient.post()
        .uri("/chat/completions")
        .bodyValue(apiRequest)
        .accept(MediaType.TEXT_EVENT_STREAM)
        .retrieve()
        .bodyToFlux(String.class)
        .retryWhen(Retry.backoff(2, Duration.ofSeconds(1))
            .filter(throwable -> isRetryableError(throwable)))
        .onErrorResume(error -> {
            log.error("Stream failed, returning error chunk", error);
            return Flux.just(LlmChunk.builder()
                .done(true)
                .finishReason("error")
                .build());
        });
}
```

**流式降级：**
- 重试 2 次（比同步少，避免长时间等待）
- 失败后返回错误 chunk，而不是抛异常
- 保证流不会突然中断

## 判断可重试错误

```java
private boolean isRetryableError(Throwable throwable) {
    // 1. 超时
    if (throwable instanceof TimeoutException) {
        return true;
    }

    // 2. 服务器错误 (5xx)
    if (throwable instanceof WebClientException) {
        String message = throwable.getMessage();
        if (message.contains("500") ||
            message.contains("502") ||
            message.contains("503") ||
            message.contains("504")) {
            return true;
        }
    }

    // 3. 限流 (429)
    if (throwable.getMessage() != null &&
        throwable.getMessage().contains("429")) {
        return true;
    }

    return false;
}
```

## 单元测试

### 测试可重试错误

```java
@Test
void testIsRetryableError_Timeout() {
    assertTrue(client.isRetryableError(new TimeoutException()));
}

@Test
void testIsRetryableError_ServerError() {
    WebClientResponseException error500 =
        WebClientResponseException.create(500, "Error", null, null, null);
    assertTrue(client.isRetryableError(error500));
}

@Test
void testIsRetryableError_RateLimit() {
    WebClientResponseException error429 =
        WebClientResponseException.create(429, "Too Many Requests", null, null, null);
    assertTrue(client.isRetryableError(error429));
}
```

### 测试不可重试错误

```java
@Test
void testIsNotRetryableError_ClientError() {
    WebClientResponseException error400 =
        WebClientResponseException.create(400, "Bad Request", null, null, null);
    assertFalse(client.isRetryableError(error400));

    WebClientResponseException error401 =
        WebClientResponseException.create(401, "Unauthorized", null, null, null);
    assertFalse(client.isRetryableError(error401));
}
```

**测试结果：** 5/5 通过 ✅

## 指数退避原理

**退避时间计算：**

```
第1次重试：等待 1s
第2次重试：等待 2s
第3次重试：等待 4s
...
最大等待：10s
```

**为什么用指数退避？**
- 避免雪崩：所有客户端同时重试会加剧服务器压力
- 快速恢复：短时间故障可以快速重试
- 长时间故障：逐渐增加等待时间，减少无效请求

## 常见问题

### 1. 重试次数耗尽

**问题：** 重试 3 次后仍然失败

**解决：**

```java
.onRetryExhaustedThrow((spec, signal) -> {
    log.error("Max retries exceeded after {} attempts", signal.totalRetries());
    return new LlmException("服务暂时不可用，请稍后再试");
})
```

### 2. 限流重试太快

**问题：** 429 错误重试太快，仍然被限流

**解决：** 增加 maxBackoff

```java
.retryWhen(Retry.backoff(3, Duration.ofSeconds(2))
    .maxBackoff(Duration.ofSeconds(30)))  // 增加到 30 秒
```

### 3. 流式输出中断

**问题：** 流式输出中途失败，前端显示异常

**解决：** 使用 `onErrorResume` 返回错误 chunk

```java
.onErrorResume(error -> {
    return Flux.just(LlmChunk.builder()
        .done(true)
        .finishReason("error")
        .build());
})
```

## 最佳实践

### 1. 记录重试日志

```java
.doOnNext(retrySignal -> {
    log.warn("Retry {}/{} after {}ms",
        retrySignal.totalRetries(),
        maxRetries,
        retrySignal.backoff().toMillis());
})
```

### 2. 区分重试策略

| 场景 | 同步调用 | 流式调用 |
|------|---------|---------|
| 最大重试次数 | 3 | 2 |
| 初始退避 | 1s | 1s |
| 最大退避 | 10s | 5s |
| 失败处理 | 抛异常 | 返回错误 chunk |

### 3. 监控重试统计

```java
private final AtomicInteger retryCount = new AtomicInteger(0);

.retryWhen(Retry.backoff(3, Duration.ofSeconds(1))
    .doAfterRetry(signal -> retryCount.incrementAndGet()))
```

## 测试结果

**所有测试：**
- ✅ 24/24 通过
- ✅ 重试逻辑正确
- ✅ 错误分类准确
- ✅ 降级策略有效

## 下一步

下一节我们将：
- 实现多模型适配
- 支持配置多个 LLM 提供商
- 动态切换模型

[下一章：第五章 数据持久化 →](../chapter-05/5.1-session-management.md)
