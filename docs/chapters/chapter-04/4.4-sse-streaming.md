# 4.4 SSE 协议与流式输出

> 本节我们实现 LLM 的流式输出，让用户实时看到 AI 生成的内容。

## 本节目标

- 理解 SSE（Server-Sent Events）协议
- 实现流式调用 LLM
- 处理 delta 增量
- 使用 Reactor Flux

## SSE 协议是什么？

**普通 HTTP 请求：**

```
客户端 → 服务器：给我完整回答
服务器 → 客户端：[等待...] [完整回答]
```

**SSE 流式请求：**

```
客户端 → 服务器：给我回答（流式）
服务器 → 客户端：你
服务器 → 客户端：好
服务器 → 客户端：！
服务器 → 客户端：我
服务器 → 客户端：是
服务器 → 客户端：AI
服务器 → 客户端：[DONE]
```

**为什么用流式？**
- 用户感知更快（不用等完整响应）
- 更好的体验（边生成边显示）
- 减少首字延迟

## 实现流式调用

### 核心代码

```java
@Override
public Flux<LlmChunk> stream(LlmRequest request) {
    // 1. 构建请求（stream = true）
    ChatCompletionRequest apiRequest = buildApiRequest(request, true);

    // 2. 发送请求（接受 SSE 流）
    return webClient.post()
        .uri("/chat/completions")
        .bodyValue(apiRequest)
        .accept(MediaType.TEXT_EVENT_STREAM)  // 关键！
        .retrieve()
        .bodyToFlux(String.class)  // Flux<String>
        .filter(line -> !line.isBlank())
        .filter(line -> !line.equals("data: [DONE]"))
        .map(line -> parseChunk(line));
}
```

**关键点：**

1. `accept(MediaType.TEXT_EVENT_STREAM)` - 告诉服务器我要流式响应
2. `bodyToFlux(String.class)` - 返回流而不是单个响应
3. 过滤空行和结束标记

### 解析 delta 增量

```java
private LlmChunk parseChunk(String json) {
    JsonNode root = objectMapper.readTree(json);
    JsonNode delta = root.path("choices").get(0).path("delta");

    // 提取内容增量
    String contentDelta = delta.path("content").asText(null);

    // 是否完成
    String finishReason = root.path("choices")
        .get(0)
        .path("finish_reason")
        .asText(null);
    boolean done = finishReason != null;

    return LlmChunk.builder()
        .delta(contentDelta)
        .done(done)
        .build();
}
```

**SSE 响应示例：**

```
data: {"choices":[{"delta":{"content":"你"},"index":0}]}

data: {"choices":[{"delta":{"content":"好"},"index":0}]}

data: {"choices":[{"delta":{"content":"！"},"index":0}]}

data: [DONE]
```

## 实际使用示例

### 示例 1：简单的流式对话

```java
@Autowired
private LlmClient llmClient;

@GetMapping("/chat/stream")
public Flux<LlmChunk> streamChat(@RequestParam String message) {
    LlmRequest request = LlmRequest.builder()
        .messages(List.of(
            LlmRequest.Message.user(message)
        ))
        .build();

    return llmClient.stream(request);
}
```

前端接收：

```javascript
const eventSource = new EventSource('/chat/stream?message=你好');

eventSource.onmessage = (event) => {
    const chunk = JSON.parse(event.data);
    if (chunk.delta) {
        console.log(chunk.delta);  // 实时打印
    }
    if (chunk.done) {
        eventSource.close();
    }
};
```

### 示例 2：累积完整内容

```java
public Mono<String> streamAndAccumulate(String message) {
    StringBuilder fullContent = new StringBuilder();

    return llmClient.stream(LlmRequest.builder()
        .messages(List.of(LlmRequest.Message.user(message)))
        .build())
    .doOnNext(chunk -> {
        if (chunk.getDelta() != null) {
            fullContent.append(chunk.getDelta());
        }
    })
    .then(Mono.just(fullContent.toString()));
}
```

### 示例 3：打印流式输出

```java
llmClient.stream(request)
    .doOnNext(chunk -> {
        if (chunk.getDelta() != null) {
            System.out.print(chunk.getDelta());  // 实时打印
        }
        if (chunk.isDone()) {
            System.out.println("\n[完成]");
        }
    })
    .blockLast();  // 等待完成
```

## 测试验证

### 集成测试

```java
@Test
void testRealStreamChat() {
    LlmRequest request = LlmRequest.builder()
        .messages(List.of(
            LlmRequest.Message.user("用一句话介绍 AI Agent")
        ))
        .build();

    StringBuilder fullContent = new StringBuilder();

    llmClient.stream(request)
        .doOnNext(chunk -> {
            if (chunk.getDelta() != null) {
                System.out.print(chunk.getDelta());
                fullContent.append(chunk.getDelta());
            }
        })
        .blockLast(Duration.ofSeconds(30));

    assertFalse(fullContent.toString().isBlank());
}
```

**实际输出：**

```
AI Agent是能够感知环境、自主决策并执行任务以实现目标的智能实体。
[完成]
```

### 测试结果

- ✅ 同步调用：通过
- ✅ 流式调用：通过
- ✅ 内容正确：AI 返回了正确的回答

## 常见问题

### 1. 流式中断

**问题：** 流式输出突然停止

**原因：** 网络问题或超时

**解决：**

```java
.timeout(Duration.ofSeconds(60))
.onErrorResume(e -> {
    log.error("Stream error", e);
    return Flux.just(LlmChunk.builder()
        .done(true)
        .build());
})
```

### 2. 中文乱码

**问题：** 中文字符显示不正常

**解决：** 确保 UTF-8 编码

```java
.defaultHeader("Content-Type", "application/json; charset=UTF-8")
```

### 3. 内存泄漏

**问题：** 长时间流式输出导致内存增长

**解决：** 使用背压（backpressure）

```java
.onBackpressureBuffer(1000)  // 限制缓冲区大小
```

## 技术要点

### Reactor Flux

**Flux vs Mono：**

| 类型 | 说明 | 返回 |
|------|------|------|
| `Mono<T>` | 0 或 1 个元素 | 单个值 |
| `Flux<T>` | 0 到 N 个元素 | 流 |

**常用操作：**

```java
flux.filter(x -> x != null)   // 过滤
    .map(x -> transform(x))    // 转换
    .doOnNext(x -> ...)        // 副作用
    .blockLast()               // 阻塞等待完成
```

### WebClient 流式请求

**同步 vs 流式：**

```java
// 同步
String response = webClient.post()
    .bodyValue(request)
    .retrieve()
    .bodyToMono(String.class)
    .block();

// 流式
Flux<String> stream = webClient.post()
    .bodyValue(request)
    .accept(MediaType.TEXT_EVENT_STREAM)
    .retrieve()
    .bodyToFlux(String.class);
```

## 下一步

下一节我们将：
- 实现 Reactor Flux 流式管道
- 优化内存管理
- 处理背压

[下一节：4.5 Reactor Flux 流式管道 →](./4.5-reactor-flux.md)
