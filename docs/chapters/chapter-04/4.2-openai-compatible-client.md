# 4.2 OpenAI å…¼å®¹å®¢æˆ·ç«¯è®¾è®¡

> æœ¬èŠ‚æˆ‘ä»¬å°†è®¾è®¡ MiniClaw çš„ LLM å®¢æˆ·ç«¯æ¥å£ï¼Œä¸ºåç»­å®ç°æ‰“ä¸‹åŸºç¡€ã€‚

## ğŸ“‹ æœ¬èŠ‚ç›®æ ‡

- ç†è§£ OpenAI API åè®®
- è®¾è®¡ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯æ¥å£
- å®šä¹‰è¯·æ±‚å’Œå“åº”æ¨¡å‹
- ä¸ºå¤šæ¨¡å‹é€‚é…åšå‡†å¤‡

## ğŸ¯ æœ¬èŠ‚è¦ç‚¹

**ä¸ºä»€ä¹ˆè¦æå‰å®šä¹‰ ToolCallï¼Ÿ**

ä½ å¯èƒ½æ³¨æ„åˆ°ï¼Œæœ¬èŠ‚çš„ä»£ç é‡Œå·²ç»åŒ…å«äº† `ToolCall` ç›¸å…³çš„æ¨¡å‹ï¼Œä½†æˆ‘ä»¬è¦åˆ°ç¬¬ 7 ç« æ‰ä¼šçœŸæ­£ä½¿ç”¨å®ƒã€‚ä¸ºä»€ä¹ˆï¼Ÿ

**æ¥å£è®¾è®¡çš„å®Œæ•´æ€§åŸåˆ™ï¼š**

LLM API åè®®æ˜¯å›ºå®šçš„ï¼Œ`ToolCall` æ˜¯ OpenAI åè®®çš„ä¸€éƒ¨åˆ†ã€‚å¦‚æœç°åœ¨ä¸å®šä¹‰ï¼š
1. åé¢æ·»åŠ æ—¶éœ€è¦ä¿®æ”¹æ¥å£ï¼ˆç ´åæ€§å˜æ›´ï¼‰
2. æµ‹è¯•ç”¨ä¾‹éœ€è¦é‡å†™
3. ä¸ç¬¦åˆ"æ¥å£ä¼˜å…ˆè®¾è®¡"åŸåˆ™

**ç±»æ¯”ï¼š**
å°±åƒè®¾è®¡ä¸€ä¸ª HTTP å®¢æˆ·ç«¯ï¼Œè™½ç„¶ä½ åªç”¨åˆ° GET å’Œ POSTï¼Œä½†æ¥å£è®¾è®¡æ—¶åº”è¯¥è€ƒè™‘ PUTã€DELETE ç­‰æ–¹æ³•ï¼Œå› ä¸º HTTP åè®®æœ¬èº«å°±æœ‰è¿™äº›æ–¹æ³•ã€‚

**å­¦ä¹ å»ºè®®ï¼š**
- ç°åœ¨ï¼šåªéœ€è¦çŸ¥é“ `ToolCall` æ˜¯ä¸ºäº†æ”¯æŒå·¥å…·è°ƒç”¨
- ç¬¬ 7 ç« ï¼šä¼šè¯¦ç»†è®²è§£å¦‚ä½•ä½¿ç”¨å®ƒ
- æš‚æ—¶ï¼šå¯ä»¥æŠŠå®ƒå½“ä½œ"é¢„ç•™ç»™æœªæ¥çš„å­—æ®µ"

---

### ä¸ºä»€ä¹ˆç”¨æ¥å£è€Œä¸æ˜¯ç›´æ¥å®ç°ï¼Ÿ

å‡ ä¹æ‰€æœ‰ä¸»æµ LLM éƒ½å…¼å®¹ OpenAI APIï¼š
- Anthropic Claudeï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
- Google Geminiï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
- å›½äº§å¤§æ¨¡å‹ï¼ˆDeepSeekã€æ™ºè°±ã€æ–‡å¿ƒç­‰ï¼‰
- æœ¬åœ°æ¨¡å‹ï¼ˆOllamaã€vLLMï¼‰

è¿™æ„å‘³ç€ï¼š**å®ç°ä¸€ä¸ª OpenAI å…¼å®¹å®¢æˆ·ç«¯ = æ”¯æŒæ‰€æœ‰æ¨¡å‹**

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### åˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸šåŠ¡å±‚ï¼ˆController/Serviceï¼‰    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LlmClient æ¥å£                  â”‚  ç»Ÿä¸€æ¥å£
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAiCompatibleLlmClient      â”‚  å®ç°ç±»
â”‚  - HTTP è¯·æ±‚æ„å»º                â”‚
â”‚  - å“åº”è§£æ                     â”‚
â”‚  - é”™è¯¯å¤„ç†                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WebFlux WebClient              â”‚  HTTP å®¢æˆ·ç«¯
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®¾è®¡åŸåˆ™ï¼š**

1. **æ¥å£æŠ½è±¡**ï¼šLlmClient å®šä¹‰æ ‡å‡†æ¥å£
2. **å®ç°åˆ†ç¦»**ï¼šOpenAiCompatibleLlmClient å®ç°å…·ä½“é€»è¾‘
3. **åè®®ç»Ÿä¸€**ï¼šä½¿ç”¨ OpenAI å…¼å®¹åè®®
4. **æ˜“äºæ‰©å±•**ï¼šæœªæ¥å¯ä»¥æ·»åŠ å…¶ä»–åè®®æ”¯æŒ

---

## ğŸ“¦ æ ¸å¿ƒæ¨¡å‹

### 1. LlmClient æ¥å£

```java
public interface LlmClient {

    /**
     * åŒæ­¥è°ƒç”¨ LLM
     * ç­‰å¾…å®Œæ•´ç»“æœåè¿”å›
     */
    LlmResponse chat(LlmRequest request);

    /**
     * æµå¼è°ƒç”¨ LLM
     * å®æ—¶è¿”å›å†…å®¹å—
     */
    Flux<LlmChunk> stream(LlmRequest request);
}
```

**ä¸¤ç§è°ƒç”¨æ¨¡å¼ï¼š**

| æ¨¡å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **åŒæ­¥** | ç­‰å¾…å®Œæ•´å“åº” | æ‰¹å¤„ç†ã€åå°ä»»åŠ¡ |
| **æµå¼** | å®æ—¶è¿”å› chunks | å¯¹è¯ã€å®æ—¶å±•ç¤º |

### 2. LlmRequest è¯·æ±‚æ¨¡å‹

```java
@Data
@Builder
public class LlmRequest {
    private List<Message> messages;        // æ¶ˆæ¯åˆ—è¡¨
    private String model;                  // æ¨¡å‹åç§°
    private Double temperature;            // æ¸©åº¦å‚æ•°
    private Integer maxTokens;             // æœ€å¤§ token
    private Boolean stream;                // æ˜¯å¦æµå¼
    private List<Map<String, Object>> tools;  // å·¥å…·å®šä¹‰
    private String toolChoice;             // å·¥å…·é€‰æ‹©ç­–ç•¥
}
```

**å…³é”®å­—æ®µè¯´æ˜ï¼š**

| å­—æ®µ | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| `messages` | List | å¯¹è¯å†å² | `[{"role": "user", "content": "ä½ å¥½"}]` |
| `model` | String | æ¨¡å‹åç§° | `"gpt-4"`, `"claude-3-opus"` |
| `temperature` | Double | éšæœºæ€§ï¼ˆ0-2ï¼‰ | `0.7`ï¼ˆå¹³è¡¡ï¼‰, `0`ï¼ˆç¡®å®šæ€§ï¼‰ |
| `maxTokens` | Integer | æœ€å¤§è¾“å‡º token | `4096` |
| `tools` | List | å·¥å…·å®šä¹‰ï¼ˆFunction Callingï¼‰ | è§ä¸‹æ–‡ |

**Message æ¨¡å‹ï¼š**

```java
@Data
@Builder
public static class Message {
    private String role;                   // è§’è‰²
    private String content;                // å†…å®¹
    private List<ToolCall> toolCalls;      // å·¥å…·è°ƒç”¨ï¼ˆassistantï¼‰
    private String toolCallId;             // å·¥å…·è°ƒç”¨ IDï¼ˆtoolï¼‰
}
```

**è§’è‰²è¯´æ˜ï¼š**

| è§’è‰² | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `system` | ç³»ç»ŸæŒ‡ä»¤ | "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹" |
| `user` | ç”¨æˆ·è¾“å…¥ | "å¸®æˆ‘å†™ä»£ç " |
| `assistant` | AI å“åº” | "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ " |
| `tool` | å·¥å…·ç»“æœ | "æ‰§è¡Œç»“æœï¼š..." |

**ä¾¿æ·æ–¹æ³•ï¼š**

```java
// åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯
Message.system("ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹")

// åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
Message.user("å¸®æˆ‘å†™ä»£ç ")

// åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯
Message.assistant("å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ ")

// åˆ›å»ºå·¥å…·ç»“æœæ¶ˆæ¯
Message.toolResult("call_123", "æ‰§è¡Œç»“æœï¼š...")
```

### 3. LlmResponse å“åº”æ¨¡å‹

```java
@Data
@Builder
public class LlmResponse {
    private String content;                // å“åº”å†…å®¹
    private List<ToolCall> toolCalls;      // å·¥å…·è°ƒç”¨åˆ—è¡¨
    private String finishReason;           // å®ŒæˆåŸå› 
    private Usage usage;                   // Token ç»Ÿè®¡
}
```

**finishReason è¯´æ˜ï¼š**

| å€¼ | è¯´æ˜ |
|----|------|
| `stop` | æ­£å¸¸ç»“æŸ |
| `length` | è¾¾åˆ°æœ€å¤§ token |
| `tool_calls` | éœ€è¦è°ƒç”¨å·¥å…· |

**Usage ç»Ÿè®¡ï¼š**

```java
@Data
@Builder
public static class Usage {
    private Integer promptTokens;       // è¾“å…¥ token
    private Integer completionTokens;   // è¾“å‡º token
    private Integer totalTokens;        // æ€» token
}
```

### 4. LlmChunk æµå¼å“åº”å—

```java
@Data
@Builder
public class LlmChunk {
    private String delta;                   // å†…å®¹å¢é‡
    private List<ToolCall> toolCalls;       // å·¥å…·è°ƒç”¨å¢é‡
    private String finishReason;            // å®ŒæˆåŸå› 
    private boolean done;                   // æ˜¯å¦ç»“æŸ
}
```

**æµå¼è¾“å‡ºåŸç†ï¼š**

```
LLM ç”Ÿæˆï¼š"ä½ å¥½ï¼Œæˆ‘æ˜¯ AI åŠ©æ‰‹"

åŒæ­¥å“åº”ï¼š
[å®Œæ•´çš„ "ä½ å¥½ï¼Œæˆ‘æ˜¯ AI åŠ©æ‰‹"]

æµå¼å“åº”ï¼ˆå¤šä¸ª chunksï¼‰ï¼š
[delta: "ä½ "]
[delta: "å¥½"]
[delta: "ï¼Œ"]
[delta: "æˆ‘æ˜¯"]
[delta: " AI"]
[delta: " åŠ©æ‰‹"]
[done: true]
```

**ä¼˜åŠ¿ï¼š**
- ç”¨æˆ·æ„ŸçŸ¥æ›´å¿«ï¼ˆè¾¹ç”Ÿæˆè¾¹æ˜¾ç¤ºï¼‰
- å‡å°‘é¦–å­—å»¶è¿Ÿ
- æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

### 5. ToolCall å·¥å…·è°ƒç”¨

**æ³¨æ„ï¼š** `ToolCall` ç›¸å…³åŠŸèƒ½åœ¨ç¬¬ 7 ç« æ‰ä¼šè¯¦ç»†è®²è§£ï¼Œè¿™é‡Œåªæ˜¯æå‰å®šä¹‰æ•°æ®æ¨¡å‹ã€‚

```java
@Data
@Builder
public class ToolCall {
    private String id;                      // è°ƒç”¨ ID
    private String type;                    // ç±»å‹ï¼ˆfunctionï¼‰
    private FunctionCall function;          // å‡½æ•°è°ƒç”¨
}
```

**Function Calling æµç¨‹ï¼š**

```
1. LLM å†³å®šè°ƒç”¨å·¥å…·
   {
     "toolCalls": [{
       "id": "call_123",
       "function": {
         "name": "get_weather",
         "arguments": "{\"city\": \"åŒ—äº¬\"}"
       }
     }]
   }

2. åº”ç”¨æ‰§è¡Œå·¥å…·
   get_weather("åŒ—äº¬") â†’ "æ™´å¤©ï¼Œ25Â°C"

3. è¿”å›å·¥å…·ç»“æœ
   Message.toolResult("call_123", "æ™´å¤©ï¼Œ25Â°C")

4. LLM åŸºäºç»“æœç»§ç»­ç”Ÿæˆ
   "åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæ°”æ¸©25Â°C"
```

**ç¬¬ 7 ç« ä¼šè¯¦ç»†è®²è§£ï¼š**
- å¦‚ä½•å®šä¹‰å·¥å…·
- å¦‚ä½•å¤„ç†å·¥å…·è°ƒç”¨
- å¦‚ä½•è¿”å›å·¥å…·ç»“æœ

---

## ğŸ” OpenAI API åè®®

### åŒæ­¥è°ƒç”¨ç¤ºä¾‹

**è¯·æ±‚ï¼š**

```http
POST /v1/chat/completions HTTP/1.1
Host: api.openai.com
Authorization: Bearer sk-xxx
Content-Type: application/json

{
  "model": "gpt-4",
  "messages": [
    {"role": "user", "content": "ä½ å¥½"}
  ],
  "temperature": 0.7
}
```

**å“åº”ï¼š**

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1700000000,
  "model": "gpt-4",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 15,
    "total_tokens": 25
  }
}
```

### æµå¼è°ƒç”¨ç¤ºä¾‹

**è¯·æ±‚ï¼š**

```http
POST /v1/chat/completions HTTP/1.1
Host: api.openai.com
Authorization: Bearer sk-xxx
Content-Type: application/json

{
  "model": "gpt-4",
  "messages": [
    {"role": "user", "content": "ä½ å¥½"}
  ],
  "stream": true
}
```

**å“åº”ï¼ˆSSE æ ¼å¼ï¼‰ï¼š**

```
data: {"id":"chatcmpl-123","choices":[{"delta":{"content":"ä½ "},"index":0}]}

data: {"id":"chatcmpl-123","choices":[{"delta":{"content":"å¥½"},"index":0}]}

data: {"id":"chatcmpl-123","choices":[{"delta":{"content":"ï¼"},"index":0}]}

data: [DONE]
```

**SSEï¼ˆServer-Sent Eventsï¼‰åè®®ï¼š**
- æ¯ä¸ª chunk ä»¥ `data:` å¼€å¤´
- ä»¥ç©ºè¡Œåˆ†éš”
- æœ€åå‘é€ `data: [DONE]`

---

## ğŸ“Š æ¨¡å‹å…¼å®¹æ€§

### ä¸»æµ LLM API å¯¹æ¯”

| æ¨¡å‹ | API å…¼å®¹æ€§ | æµå¼æ”¯æŒ | Function Calling |
|------|-----------|----------|-----------------|
| **OpenAI GPT** | åŸç”Ÿ | âœ… | âœ… |
| **Anthropic Claude** | å…¼å®¹æ¨¡å¼ | âœ… | âœ… |
| **Google Gemini** | å…¼å®¹æ¨¡å¼ | âœ… | âœ… |
| **DeepSeek** | å®Œå…¨å…¼å®¹ | âœ… | âœ… |
| **æ™ºè°± GLM** | å®Œå…¨å…¼å®¹ | âœ… | âœ… |
| **Ollama** | å®Œå…¨å…¼å®¹ | âœ… | âŒ |

**ç»“è®ºï¼š** å®ç° OpenAI åè®®å®¢æˆ·ç«¯ = æ”¯æŒæ‰€æœ‰ä¸»æµæ¨¡å‹

---

## ğŸ“ è®¾è®¡æ€è€ƒ

### ä¸ºä»€ä¹ˆç”¨æ¥å£è€Œä¸æ˜¯ç›´æ¥å®ç°ï¼Ÿ

**çµæ´»æ€§ï¼š**

```java
// å¯ä»¥è½»æ¾åˆ‡æ¢å®ç°
LlmClient client = new OpenAiCompatibleLlmClient("gpt-4");

// æœªæ¥å¯ä»¥æ·»åŠ å…¶ä»–å®ç°
LlmClient client = new AnthropicClient("claude-3");
LlmClient client = new GeminiClient("gemini-pro");
```

**æµ‹è¯•æ€§ï¼š**

```java
// å¯ä»¥è½»æ¾ mock
@MockBean
LlmClient llmClient;

when(llmClient.chat(any()))
    .thenReturn(LlmResponse.builder()
        .content("æµ‹è¯•å“åº”")
        .build());
```

### ä¸ºä»€ä¹ˆæ”¯æŒåŒæ­¥å’Œæµå¼ä¸¤ç§æ¨¡å¼ï¼Ÿ

**ä½¿ç”¨åœºæ™¯ä¸åŒï¼š**

```java
// åŒæ­¥ï¼šé€‚åˆæ‰¹å¤„ç†
List<String> results = prompts.stream()
    .map(prompt -> llmClient.chat(buildRequest(prompt)).getContent())
    .toList();

// æµå¼ï¼šé€‚åˆå®æ—¶å¯¹è¯
@GetMapping("/chat/stream")
public Flux<LlmChunk> streamChat(@RequestParam String prompt) {
    return llmClient.stream(buildRequest(prompt));
}
```

---

## ğŸ”§ å®é™…åº”ç”¨ç¤ºä¾‹

### åœºæ™¯ 1ï¼šç®€å•å¯¹è¯

```java
// æ„å»ºè¯·æ±‚
LlmRequest request = LlmRequest.builder()
    .messages(List.of(
        Message.user("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
    ))
    .build();

// åŒæ­¥è°ƒç”¨
LlmResponse response = llmClient.chat(request);
System.out.println(response.getContent());
```

### åœºæ™¯ 2ï¼šå¤šè½®å¯¹è¯

```java
List<Message> messages = new ArrayList<>();

// ç¬¬ä¸€è½®
messages.add(Message.user("ä»€ä¹ˆæ˜¯ Javaï¼Ÿ"));
LlmResponse response1 = llmClient.chat(LlmRequest.builder()
    .messages(messages)
    .build());
messages.add(Message.assistant(response1.getContent()));

// ç¬¬äºŒè½®
messages.add(Message.user("å®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ"));
LlmResponse response2 = llmClient.chat(LlmRequest.builder()
    .messages(messages)
    .build());
```

### åœºæ™¯ 3ï¼šæµå¼è¾“å‡º

```java
Flux<LlmChunk> chunks = llmClient.stream(LlmRequest.builder()
    .messages(List.of(Message.user("å†™ä¸€é¦–è¯—")))
    .build());

chunks.subscribe(chunk -> {
    if (chunk.getDelta() != null) {
        System.out.print(chunk.getDelta());  // å®æ—¶æ‰“å°
    }
    if (chunk.isDone()) {
        System.out.println("\n[å®Œæˆ]");
    }
});
```

### åœºæ™¯ 4ï¼šFunction Calling

**æ³¨æ„ï¼š** è¿™ä¸ªåœºæ™¯åœ¨ç¬¬ 7 ç« ä¼šè¯¦ç»†è®²è§£ï¼Œè¿™é‡Œåªæ˜¯å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `ToolCall`ã€‚

```java
// å®šä¹‰å·¥å…·
Map<String, Object> weatherTool = Map.of(
    "type", "function",
    "function", Map.of(
        "name", "get_weather",
        "description", "è·å–åŸå¸‚å¤©æ°”",
        "parameters", Map.of(
            "type", "object",
            "properties", Map.of(
                "city", Map.of("type", "string", "description", "åŸå¸‚åç§°")
            )
        )
    )
);

// è°ƒç”¨ LLM
LlmResponse response = llmClient.chat(LlmRequest.builder()
    .messages(List.of(Message.user("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")))
    .tools(List.of(weatherTool))
    .build());

// å¤„ç†å·¥å…·è°ƒç”¨
if (response.hasToolCalls()) {
    ToolCall toolCall = response.getToolCalls().get(0);
    String city = parseArguments(toolCall.getFunction().getArguments());
    String result = getWeather(city);

    // è¿”å›å·¥å…·ç»“æœ
    Message.toolResult(toolCall.getId(), result);
}
```

**å®Œæ•´å®ç°è§ç¬¬ 7 ç« ï¼šå·¥å…·ç³»ç»Ÿä¸å®‰å…¨æ§åˆ¶**

---

## âœ… éªŒè¯æ¥å£è®¾è®¡

### ç¼–è¯‘æ£€æŸ¥

```bash
cd miniclaw-learn
mvn clean compile
```

**é¢„æœŸè¾“å‡ºï¼š**

```
[INFO] BUILD SUCCESS
```

### ç»“æ„æ£€æŸ¥

```bash
tree src/main/java/com/miniclaw/llm/
```

**é¢„æœŸç»“æ„ï¼š**

```
llm/
â”œâ”€â”€ LlmClient.java
â”œâ”€â”€ exception/
â”‚   â””â”€â”€ LlmException.java
â””â”€â”€ model/
    â”œâ”€â”€ LlmRequest.java
    â”œâ”€â”€ LlmResponse.java
    â”œâ”€â”€ LlmChunk.java
    â””â”€â”€ ToolCall.java
```

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. ä¸ºä»€ä¹ˆè¦åŒºåˆ† Message.roleï¼Ÿ

ä¸åŒè§’è‰²æœ‰ä¸åŒç”¨é€”ï¼š
- `system`ï¼šè®¾ç½® AI è¡Œä¸º
- `user`ï¼šç”¨æˆ·è¾“å…¥
- `assistant`ï¼šAI å“åº”
- `tool`ï¼šå·¥å…·è¿”å›

### 2. LlmChunk å’Œ LlmResponse çš„åŒºåˆ«ï¼Ÿ

- `LlmResponse`ï¼šå®Œæ•´å“åº”ï¼ˆåŒæ­¥ï¼‰
- `LlmChunk`ï¼šå¢é‡å“åº”å—ï¼ˆæµå¼ï¼‰

### 3. ToolCall ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ï¼Ÿ

å½“ LLM å†³å®šè°ƒç”¨å·¥å…·æ—¶ï¼ˆFunction Callingï¼‰ï¼Œç¬¬ 7 ç« ä¼šè¯¦ç»†è®²è§£ã€‚

---

## ğŸ“š æ‰©å±•é˜…è¯»

- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/api-reference/chat)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Server-Sent Events åè®®](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)

---

## ğŸ¯ ä¸‹ä¸€èŠ‚

ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†ï¼š
- å®ç° OpenAiCompatibleLlmClient
- å¤„ç† HTTP è¯·æ±‚å’Œå“åº”
- è§£æ JSON æ•°æ®

[ä¸‹ä¸€èŠ‚ï¼š4.3 åŒæ­¥è°ƒç”¨å®ç° â†’](./4.3-sync-implementation.md)
